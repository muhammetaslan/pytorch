{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\"\"\"  \n",
    "The torch.nn import gives us access to some helpful neural network things, such as various\n",
    "neural network layer types \n",
    "(things like regular fully-connected layers, convolutional layers (for imagery), recurrent layers...etc).\n",
    "\"\"\"\n",
    "import torch.nn as nn \n",
    "\"\"\"\n",
    "The torch.nn.functional area specifically gives us access to some handy functions that we might not \n",
    "want to write ourselves. We will be using the relu or \"rectified linear\" activation \n",
    "function for our neurons. Instead of writing all of the code for these things, we can just import them, \n",
    "\"\"\"\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "train = datasets.MNIST('', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "test = datasets.MNIST('', train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "All we're doing is just defining values for some layers, \n",
    "we're calling them fc1, fc2...etc, but you could call them whatever you wanted.\n",
    "\"\"\"\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #  The fc just stands for fully connected\n",
    "        self.fc1 = nn.Linear(28*28,64)\n",
    "        self.fc2 = nn.Linear(64,64)\n",
    "        self.fc3 = nn.Linear(64,64)\n",
    "        self.fc4 = nn.Linear(64,10)\n",
    "    \n",
    "    \"\"\"The simplest neural network is fully connected, and feed-forward, meaning we go from input to output.\n",
    "    In one side and out the other in a \"forward\" manner.  \"\"\"\n",
    "    ## forward propagation\n",
    "    def forward(self, x):\n",
    "        # her katman aktivasyon fonksiyonu ile çalışır\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        \n",
    "        # son layer da relu girmez\n",
    "        x = self.fc4(x)\n",
    "        # multi class output layer için softmax daha iyidir.\n",
    "        # binary classification için ise sigmoid()\n",
    "        # dim = 1 demek softmax daki oluşan 10 neuron için oluşan olasıkların toplamı 1 olmalı demek\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "#our nn object\n",
    "net = Net()\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Şimdi random bir veri oluşturup kendi ağımıza input olarak vereceğiz\"\"\"\n",
    "\n",
    "X = torch.rand((28,28))\n",
    "\n",
    "# Our neural network wants this to be flattened,\n",
    "\n",
    "X = X.view(-1,28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4482, -2.2557, -2.4065, -2.2806, -2.2526, -2.3749, -2.3015, -2.1830,\n",
       "         -2.2501, -2.3021]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(X)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.3942e-05, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\"\"\"\n",
    "loss function gerçeklik ile nn deb gelen verileri karşılaştırır.\n",
    "\"\"\"\n",
    "#loss_function = nn.CrossEntropyLoss()\n",
    "# lr is learing rate\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "\"\"\"\n",
    "So, for each epoch, and for each batch in our dataset, what do we do?\n",
    "\n",
    "Grab the features (X) and labels (y) from current batch\n",
    "Zero the gradients (net.zero_grad)\n",
    "Pass the data through the network\n",
    "Calculate the loss\n",
    "Adjust weights in the network with the hopes of decreasing loss\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        # data is the batch of the features and labels\n",
    "        X , y = data\n",
    "        # her batch öncesi gradientler sıfırlanır loss hesaplama daha verimli olması için\n",
    "        net.zero_grad()\n",
    "        # veriyi view ile reshape yapıp flatten hale getiriyoruz\n",
    "        output = net(X.view(-1,28*28))\n",
    "        # calc and grab the loss value\n",
    "        loss = F.nll_loss(output, y) \n",
    "        # apply this loss backwards thru the network's parameters\n",
    "        loss.backward()\n",
    "        # attempt to optimize weights to account for loss/gradients\n",
    "        optimizer.step()  \n",
    "    print(loss)  # print loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.975\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# eğittiğimiz modeli testset ile doğruluk oranı için deneyeceğiz\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1,784))\n",
    "        #print(output)\n",
    "        for idx, i in enumerate(output):\n",
    "            #print(torch.argmax(i), y[idx])\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X[4].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "# valiede etmek için bu yeterli, eğittiğimiz net modeline verdiğimiz X verisine ait inputkarın çıkrılarını argmax\n",
    "# ile alarak test edebiliriz.\n",
    "print(torch.argmax(net(X[4].view(-1,784))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
